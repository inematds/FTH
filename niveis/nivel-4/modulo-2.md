---
layout: page
title: "M√≥dulo 4.2: Sim-to-Real Transfer"
permalink: /niveis/nivel-4/modulo-2/
---

# ü§ñ M√≥dulo 4.2: Sim-to-Real Transfer

**Da simula√ß√£o perfeita para o mundo ca√≥tico: domine a arte de transferir IA para rob√¥s reais**

---

## üìã Informa√ß√µes do M√≥dulo

| Atributo | Detalhes |
|----------|----------|
| **Dura√ß√£o estimada** | 10-15 horas |
| **N√≠vel** | Profissional |
| **Pr√©-requisitos** | N√≠vel 3 + M√≥dulo 4.1 |
| **Tipo** | T√©cnico + Pr√°tico |

---

## üéØ Objetivos de Aprendizado

Ao completar este m√≥dulo, voc√™ ser√° capaz de:

- ‚úÖ Entender o "domain gap" entre simula√ß√£o e realidade
- ‚úÖ Aplicar t√©cnicas de domain randomization
- ‚úÖ Realizar system identification de rob√¥s reais
- ‚úÖ Fine-tunar pol√≠ticas treinadas em simula√ß√£o
- ‚úÖ Fazer deploy seguro de IA em hardware
- ‚úÖ Debugar e troubleshoot problemas de Sim2Real
- ‚úÖ Monitorar rob√¥s em produ√ß√£o

---

## üìö Conte√∫do Te√≥rico

### 1. O Desafio do Sim-to-Real

#### 1.1 Por que Pol√≠ticas Falham no Mundo Real?

Voc√™ treinou seu rob√¥ perfeitamente no Isaac Sim. Ele caminha, desvia de obst√°culos, pega objetos. Taxa de sucesso: 95%.

**A√≠ voc√™ transfere para o rob√¥ real e...**

‚ùå Ele cai no primeiro passo
‚ùå Sensores retornam dados ruidosos
‚ùå Lat√™ncia de rede atrasa comandos
‚ùå Bateria fraca muda din√¢mica
‚ùå Piso escorregadio vs simulado

**Taxa de sucesso no real:** 20%

---

#### 1.2 O "Domain Gap" (Lacuna de Dom√≠nio)

**Diferen√ßas entre Simula√ß√£o e Realidade:**

| Aspecto | Simula√ß√£o | Realidade |
|---------|-----------|-----------|
| **F√≠sica** | Determinist√≠ca, perfeita | Ruidosa, imperfeita |
| **Sensores** | Zero ru√≠do | Ru√≠do, drift, falhas |
| **Atuadores** | Resposta instant√¢nea | Lat√™ncia, backlash |
| **Ambiente** | Controlado | Imprevis√≠vel |
| **Computa√ß√£o** | Ilimitada | Limitada (bateria, CPU) |
| **Tempo** | Aceler√°vel (10x) | Tempo real |

**Exemplo concreto:**

```python
# Simula√ß√£o
joint_position = robot.get_joint_position("left_knee")
# Retorna: 1.5708 (sempre exato)

# Realidade
joint_position = robot.get_joint_position("left_knee")
# Retorna: 1.5701, 1.5715, 1.5693, ... (varia)
# + √Äs vezes retorna None (sensor perdeu sinal)
# + Lat√™ncia de 20-50ms
```

---

#### 1.3 Abordagens para Sim2Real

**Abordagem 1: Simula√ß√£o Ultra-Realista**

Fazer a simula√ß√£o ser t√£o real quanto poss√≠vel.

**Pr√≥s:**
- ‚úÖ Transfere melhor
- ‚úÖ Menos ajustes no real

**Contras:**
- ‚ùå Muito custoso computacionalmente
- ‚ùå Imposs√≠vel replicar TODA realidade
- ‚ùå Treino mais lento

---

**Abordagem 2: Domain Randomization**

Tornar a simula√ß√£o propositalmente DIVERSA e ruidosa.

**Pr√≥s:**
- ‚úÖ Pol√≠tica aprende a ser robusta
- ‚úÖ Generaliza melhor
- ‚úÖ Mais usado na pr√°tica

**Contras:**
- ‚ùå Requer mais amostras de treino
- ‚ùå Pode ser "conservadora" demais

---

**Abordagem 3: H√≠brido (Sim + Fine-tuning no Real)**

Treina na simula√ß√£o, ajusta com dados reais.

**Pr√≥s:**
- ‚úÖ Melhor de dois mundos
- ‚úÖ Menos dados reais necess√°rios

**Contras:**
- ‚ùå Requer acesso ao rob√¥ real
- ‚ùå Risco de overfit no ambiente espec√≠fico

---

### 2. Domain Randomization

#### 2.1 Conceito

**Ideia:** Se a pol√≠tica funciona em 1000 vers√µes diferentes da simula√ß√£o, ela funcionar√° na realidade (que √© apenas "mais uma vers√£o").

**Par√¢metros para Randomizar:**

**A) F√≠sica**
```python
# A cada epis√≥dio, variar:
gravity = random.uniform(9.6, 10.0)  # Terra varia por altitude
friction = random.uniform(0.3, 1.2)  # Piso liso vs √°spero
mass = random.uniform(0.9, 1.1) * nominal_mass  # Toler√¢ncia fabrica√ß√£o
```

**B) Visual**
```python
# C√¢mera / Vis√£o
lighting = random.choice(['bright', 'dim', 'mixed'])
camera_noise = add_gaussian_noise(image, std=random.uniform(0, 0.1))
color_shift = random_hue_saturation(image)
occlusion = randomly_block_parts_of_image(image, prob=0.1)
```

**C) Sensores**
```python
# IMU (equil√≠brio)
imu_reading = true_value + random.normal(0, 0.05)  # Ru√≠do
imu_drift = accumulated_error * timestep  # Drift ao longo do tempo

# Encoders dos motores
encoder_delay = random.uniform(0, 50)  # ms de lat√™ncia
encoder_dropout = (random.random() < 0.02)  # 2% de falha
```

**D) Atuadores**
```python
# Motores
motor_force = command * random.uniform(0.95, 1.05)  # Varia√ß√£o
motor_delay = random.uniform(10, 30)  # ms
backlash = random.uniform(0, 2)  # graus de folga
```

---

#### 2.2 Implementa√ß√£o no Isaac Sim

**C√≥digo de exemplo:**

```python
import omni
from omni.isaac.core import World
from omni.isaac.core.utils.nucleus import get_assets_root_path
import numpy as np

class DomainRandomizer:
    def __init__(self, world: World):
        self.world = world

    def randomize_physics(self):
        """Randomiza par√¢metros f√≠sicos do ambiente"""

        # 1. Gravidade (¬±5%)
        gravity_scale = np.random.uniform(0.95, 1.05)
        self.world.get_physics_context().set_gravity(
            -9.81 * gravity_scale
        )

        # 2. Fric√ß√£o do ch√£o (0.3 a 1.2)
        ground = self.world.scene.get_object("ground_plane")
        friction = np.random.uniform(0.3, 1.2)
        ground.get_applied_physics_material().set_static_friction(friction)
        ground.get_applied_physics_material().set_dynamic_friction(friction)

        # 3. Massa do rob√¥ (¬±10%)
        robot = self.world.scene.get_object("bumi")
        for link in robot.get_links():
            original_mass = link.get_mass()
            new_mass = original_mass * np.random.uniform(0.9, 1.1)
            link.set_mass(new_mass)

    def randomize_visuals(self):
        """Randomiza apar√™ncia visual"""

        # 1. Ilumina√ß√£o
        lights = self.world.stage.GetPrimAtPath("/World/Lights")
        intensity = np.random.uniform(500, 3000)
        for light in lights.GetChildren():
            light.GetAttribute("intensity").Set(intensity)

        # 2. Cor do ch√£o
        ground = self.world.stage.GetPrimAtPath("/World/ground")
        color = np.random.uniform(0.2, 0.9, size=3)  # RGB
        ground.GetAttribute("color").Set(color)

        # 3. Posi√ß√£o de objetos aleat√≥rios (distratores)
        for i in range(np.random.randint(0, 5)):
            pos = np.random.uniform(-2, 2, size=3)
            pos[2] = 0.5  # altura fixa
            self.spawn_random_object(pos)

    def randomize_sensors(self, sensor_data):
        """Adiciona ru√≠do a leituras de sensores"""

        # 1. IMU (aceler√¥metro + girosc√≥pio)
        imu_noise = np.random.normal(0, 0.05, size=sensor_data['imu'].shape)
        sensor_data['imu'] += imu_noise

        # 2. Encoders (posi√ß√£o das juntas)
        encoder_noise = np.random.normal(0, 0.01, size=sensor_data['joints'].shape)
        sensor_data['joints'] += encoder_noise

        # 3. Dropout (2% de chance de perder leitura)
        if np.random.random() < 0.02:
            sensor_data['joints'] = None

        # 4. C√¢mera
        if 'camera' in sensor_data:
            # Adiciona ru√≠do gaussiano
            noise = np.random.normal(0, 10, size=sensor_data['camera'].shape)
            sensor_data['camera'] = np.clip(sensor_data['camera'] + noise, 0, 255)

        return sensor_data

    def randomize_actuators(self, action):
        """Simula imperfei√ß√µes dos motores"""

        # 1. For√ßa vari√°vel (¬±5%)
        force_variation = np.random.uniform(0.95, 1.05, size=action.shape)
        action = action * force_variation

        # 2. Lat√™ncia (10-30ms)
        # (requer buffer de a√ß√µes passadas)
        delay_steps = np.random.randint(1, 3)  # 1-3 steps @ 100Hz = 10-30ms
        action = self.action_buffer[-delay_steps]

        # 3. Saturation (motores t√™m limite)
        action = np.clip(action, -1.0, 1.0)

        # 4. Dead zone (pequenos comandos s√£o ignorados)
        action[np.abs(action) < 0.05] = 0

        return action

# Uso durante treino
world = World()
randomizer = DomainRandomizer(world)

for episode in range(10000):
    # A cada epis√≥dio, randomizar tudo
    randomizer.randomize_physics()
    randomizer.randomize_visuals()

    world.reset()

    for step in range(1000):
        # Observa√ß√£o com ru√≠do
        obs = get_observations()
        obs = randomizer.randomize_sensors(obs)

        # A√ß√£o da pol√≠tica
        action = policy.predict(obs)

        # A√ß√£o com imperfei√ß√µes
        action = randomizer.randomize_actuators(action)

        # Executa
        world.step(action)
```

---

#### 2.3 Boas Pr√°ticas de Randomiza√ß√£o

**1. Comece Simples, Aumente Gradualmente**

```python
# Fase 1: Sem randomiza√ß√£o (baseline)
randomization_level = 0.0

# Fase 2: Randomiza√ß√£o leve
randomization_level = 0.3

# Fase 3: Randomiza√ß√£o agressiva
randomization_level = 1.0
```

**2. Randomize o que Importa**

N√£o randomize tudo cegamente. Foque nas diferen√ßas reais.

**Exemplo:**
- ‚úÖ Randomizar fric√ß√£o (pisos variam muito)
- ‚úÖ Randomizar lat√™ncia (Wi-Fi varia)
- ‚ùå Randomizar cores aleatoriamente (se seu rob√¥ sempre vai atuar em escrit√≥rios cinzas)

**3. Valide com "Sanity Check"**

Grave v√≠deos da simula√ß√£o randomizada. Parecem plaus√≠veis?

- ‚úÖ Rob√¥ caminhando em pisos diferentes: OK
- ‚ùå Rob√¥ flutuando porque gravidade ficou negativa: N√ÉO OK

---

### 3. System Identification

#### 3.1 O que √©?

**System Identification:** Processo de estimar os par√¢metros reais do rob√¥ f√≠sico.

**Por que fazer?**
- Simula√ß√£o usa par√¢metros nominais (do manual)
- Rob√¥ real tem varia√ß√µes de fabrica√ß√£o
- Desgaste altera par√¢metros ao longo do tempo

**Par√¢metros a Identificar:**

| Par√¢metro | Nominal (Manual) | Real (Medido) |
|-----------|------------------|---------------|
| Massa total | 8.0 kg | 8.3 kg |
| Fric√ß√£o juntas | 0.01 Nm | 0.015 Nm |
| In√©rcia link | 0.05 kg¬∑m¬≤ | 0.053 kg¬∑m¬≤ |
| Lat√™ncia motores | 5 ms | 18 ms |
| Constante motor | 0.05 Nm/A | 0.048 Nm/A |

---

#### 3.2 T√©cnicas de Identifica√ß√£o

**M√©todo 1: An√°lise de Resposta ao Degrau**

Aplique comando fixo, observe resposta.

```python
import numpy as np
import matplotlib.pyplot as plt

def identify_motor_response(robot, joint_name):
    """
    Identifica constante de tempo e ganho do motor
    """
    # 1. Aplicar comando step
    robot.set_joint_effort(joint_name, 1.0)  # 100% torque

    # 2. Registrar posi√ß√£o ao longo do tempo
    positions = []
    times = []

    for t in np.arange(0, 2.0, 0.01):  # 2 segundos @ 100Hz
        pos = robot.get_joint_position(joint_name)
        positions.append(pos)
        times.append(t)
        time.sleep(0.01)

    # 3. Fit modelo de 1¬™ ordem: y(t) = K(1 - e^(-t/œÑ))
    from scipy.optimize import curve_fit

    def model(t, K, tau):
        return K * (1 - np.exp(-t / tau))

    params, _ = curve_fit(model, times, positions)
    K, tau = params

    print(f"Ganho (K): {K:.3f} rad")
    print(f"Constante de tempo (œÑ): {tau:.3f} s")

    # 4. Plotar
    plt.plot(times, positions, label='Real')
    plt.plot(times, model(times, K, tau), '--', label='Modelo')
    plt.legend()
    plt.show()

    return K, tau
```

**Interpreta√ß√£o:**
- `K` (ganho): Quanto o motor se move para comando m√°ximo
- `œÑ` (tau): Qu√£o r√°pido responde (menor = mais r√°pido)

---

**M√©todo 2: System ID via Otimiza√ß√£o**

Rode simula√ß√£o com par√¢metros vari√°veis at√© match com real.

```python
def optimize_simulation_params(real_robot_data, sim_robot):
    """
    Ajusta par√¢metros da simula√ß√£o para match com dados reais
    """
    from scipy.optimize import minimize

    def loss_function(params):
        """
        Roda simula√ß√£o com params e calcula erro vs real
        """
        mass, friction, inertia = params

        # Atualizar simula√ß√£o
        sim_robot.set_mass(mass)
        sim_robot.set_friction(friction)
        sim_robot.set_inertia(inertia)

        # Rodar mesmo experimento que no rob√¥ real
        sim_trajectory = run_experiment(sim_robot)

        # Calcular dist√¢ncia entre trajet√≥rias
        error = np.mean((sim_trajectory - real_robot_data) ** 2)
        return error

    # Otimizar
    initial_params = [8.0, 0.01, 0.05]  # Valores nominais
    bounds = [(7.0, 9.0), (0.005, 0.02), (0.04, 0.06)]

    result = minimize(
        loss_function,
        initial_params,
        bounds=bounds,
        method='L-BFGS-B'
    )

    optimal_params = result.x
    print(f"Par√¢metros identificados: {optimal_params}")

    return optimal_params
```

---

**M√©todo 3: Gray-Box Identification com ML**

Use rede neural para aprender res√≠duos (diferen√ßas n√£o modeladas).

```python
import torch
import torch.nn as nn

class ResidualDynamicsModel(nn.Module):
    """
    Aprende a diferen√ßa entre modelo nominal e real
    """
    def __init__(self, state_dim, action_dim):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(state_dim + action_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 128),
            nn.ReLU(),
            nn.Linear(128, state_dim)
        )

    def forward(self, state, action):
        x = torch.cat([state, action], dim=-1)
        residual = self.net(x)
        return residual

# Treinar com dados do rob√¥ real
model = ResidualDynamicsModel(state_dim=18, action_dim=12)

for epoch in range(100):
    for state, action, next_state in real_robot_dataset:
        # Predi√ß√£o do modelo nominal (simula√ß√£o)
        nominal_next = simulate_step(state, action)

        # Residual real
        true_residual = next_state - nominal_next

        # Predi√ß√£o do modelo ML
        pred_residual = model(state, action)

        # Loss
        loss = nn.MSELoss()(pred_residual, true_residual)
        loss.backward()
        optimizer.step()

# Agora, durante simula√ß√£o:
# next_state = simulate_step(state, action) + model(state, action)
```

---

### 4. Fine-tuning On-Robot (Safety First!)

#### 4.1 Por que Fine-tunar?

Mesmo com domain randomization perfeito, ajustes finais no rob√¥ real melhoram performance em 10-30%.

**Mas cuidado:** Treinar no rob√¥ real pode quebr√°-lo!

---

#### 4.2 Protocolo de Seguran√ßa

**Antes de ligar o rob√¥:**

```markdown
CHECKLIST DE SEGURAN√áA

Hardware:
- [ ] √Årea de 3m x 3m livre de obst√°culos
- [ ] Piso antiderrapante ou tapete
- [ ] Almofadas/colch√µes ao redor (amortecer quedas)
- [ ] Bot√£o de emerg√™ncia acess√≠vel (< 2m de dist√¢ncia)
- [ ] Bateria carregada mas n√£o ao m√°ximo (80% ideal)
- [ ] Inspe√ß√£o visual: parafusos apertados, cabos firmes

Software:
- [ ] Limites de torque configurados (50% do m√°ximo)
- [ ] Watchdog timer ativo (desliga ap√≥s 100ms sem comando)
- [ ] Kill switch via rede (SSH remoto)
- [ ] Logging ativo (registrar tudo!)
- [ ] Backup da pol√≠tica anterior (rollback f√°cil)

Equipe:
- [ ] 2+ pessoas presentes (1 no computador, 1 pronta pra segurar rob√¥)
- [ ] Todos usam √≥culos de prote√ß√£o
- [ ] Celular carregado (ligar pra suporte se necess√°rio)
- [ ] Plano de emerg√™ncia definido
```

---

#### 4.3 Estrat√©gias de Fine-tuning Seguro

**Estrat√©gia 1: Inicializa√ß√£o Segura (Safe Exploration)**

Comece de poses conservadoras, aumente risco gradualmente.

```python
class SafeExploration:
    def __init__(self, robot):
        self.robot = robot
        self.episode_count = 0

    def get_initial_pose(self):
        """Pose inicial depende do progresso"""
        if self.episode_count < 10:
            # Muito seguro: joelhos flexionados, centro de massa baixo
            return "crouch_pose"
        elif self.episode_count < 50:
            # Moderado: em p√© mas joelhos levemente flexionados
            return "standing_safe"
        else:
            # Normal: pode come√ßar de qualquer pose
            return "random_pose"

    def scale_actions(self, action):
        """Escala a√ß√µes agressivas no in√≠cio"""
        if self.episode_count < 20:
            # Primeiros epis√≥dios: max 30% de torque
            scale = 0.3
        elif self.episode_count < 100:
            # Epis√≥dios iniciais: max 60%
            scale = 0.6
        else:
            # Ap√≥s 100 epis√≥dios: sem limita√ß√µes
            scale = 1.0

        return action * scale
```

---

**Estrat√©gia 2: Human-in-the-Loop**

Humano pode intervir e corrigir o rob√¥.

```python
class HumanSupervisor:
    def __init__(self, robot):
        self.robot = robot
        self.intervention_count = 0

    def should_intervene(self, state):
        """Detecta situa√ß√µes perigosas"""

        # 1. Vai cair?
        if abs(state['base_orientation_x']) > 0.3:  # > 17 graus
            return True, "Inclina√ß√£o excessiva"

        # 2. Torques muito altos?
        if any(state['joint_efforts'] > 20.0):  # Nm
            return True, "Torque perigoso"

        # 3. Velocidade angular alta?
        if np.linalg.norm(state['angular_velocity']) > 3.0:  # rad/s
            return True, "Girando r√°pido demais"

        return False, None

    def intervene(self):
        """Para rob√¥ e registra interven√ß√£o"""
        print("üö® INTERVEN√á√ÉO HUMANA!")
        self.robot.emergency_stop()
        self.intervention_count += 1

        # Registrar para aprendizado
        self.log_intervention(state, action, reason)

        # Humano corrige manualmente
        print("Mova o rob√¥ para pose segura e pressione ENTER")
        input()

    def collect_correction(self):
        """Registra corre√ß√£o humana como dado de treino"""
        # Estado perigoso -> A√ß√£o humana (corre√ß√£o)
        # Isso vira dado de treino supervisionado
        return (state_before, human_action)

# Loop de treino
supervisor = HumanSupervisor(robot)

while True:
    state = robot.get_state()

    # Predi√ß√£o da pol√≠tica
    action = policy.predict(state)

    # Humano pode intervir
    should_stop, reason = supervisor.should_intervene(state)
    if should_stop:
        supervisor.intervene()
        continue

    # Executa a√ß√£o
    robot.step(action)
```

---

**Estrat√©gia 3: Sim-to-Real Gradual**

Treina em simula√ß√µes cada vez mais realistas.

```python
# N√≠vel 0: Simula√ß√£o limpa
train_policy(sim_clean, episodes=1000)

# N√≠vel 1: Simula√ß√£o com leve randomiza√ß√£o
train_policy(sim_light_random, episodes=500, init_from_previous=True)

# N√≠vel 2: Simula√ß√£o com randomiza√ß√£o agressiva
train_policy(sim_heavy_random, episodes=500, init_from_previous=True)

# N√≠vel 3: Simula√ß√£o com par√¢metros identificados do rob√¥ real
train_policy(sim_matched_to_real, episodes=200, init_from_previous=True)

# N√≠vel 4: Fine-tuning no rob√¥ real (poucos epis√≥dios!)
train_policy(real_robot, episodes=50, init_from_previous=True, safe_mode=True)
```

---

### 5. Deployment em Produ√ß√£o

#### 5.1 Arquitetura de Software

**Stack t√≠pico para rob√¥ em produ√ß√£o:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         APLICA√á√ÉO / UI                  ‚îÇ  ‚Üê Dashboard, API REST
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ      ORQUESTRA√á√ÉO (ROS 2)              ‚îÇ  ‚Üê Nodes, topics, services
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ PERCEP√á√ÉO   ‚îÇ  CONTROLE   ‚îÇ  NAVEGA√á√ÉO ‚îÇ
‚îÇ (Vis√£o, IA) ‚îÇ  (Motores)  ‚îÇ  (SLAM)    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ         MIDDLEWARE (DDS)                ‚îÇ  ‚Üê Comunica√ß√£o entre nodes
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ      DRIVERS DE HARDWARE                ‚îÇ  ‚Üê Interface com sensores/atuadores
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ         HARDWARE F√çSICO                 ‚îÇ  ‚Üê Rob√¥ Bumi, Unitree, etc
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

#### 5.2 Containeriza√ß√£o com Docker

**Por que usar Docker?**
- ‚úÖ Ambiente consistente (dev = prod)
- ‚úÖ F√°cil atualiza√ß√£o remota
- ‚úÖ Rollback r√°pido se algo quebrar
- ‚úÖ Isola depend√™ncias (n√£o quebra sistema)

**Dockerfile exemplo:**

```dockerfile
# Base: ROS 2 Humble + CUDA (para IA)
FROM nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04

# Instalar ROS 2
RUN apt-get update && apt-get install -y \
    curl \
    gnupg2 \
    lsb-release

RUN curl -sSL https://raw.githubusercontent.com/ros/rosdistro/master/ros.key | apt-key add -
RUN echo "deb http://packages.ros.org/ros2/ubuntu $(lsb_release -cs) main" > /etc/apt/sources.list.d/ros2.list

RUN apt-get update && apt-get install -y \
    ros-humble-desktop \
    python3-pip

# Instalar depend√™ncias Python
COPY requirements.txt /tmp/
RUN pip3 install -r /tmp/requirements.txt

# Copiar c√≥digo da aplica√ß√£o
WORKDIR /app
COPY src/ /app/src/
COPY launch/ /app/launch/
COPY config/ /app/config/

# Vari√°veis de ambiente
ENV ROS_DOMAIN_ID=42
ENV PYTHONUNBUFFERED=1

# Source ROS 2
RUN echo "source /opt/ros/humble/setup.bash" >> ~/.bashrc

# Entry point
CMD ["ros2", "launch", "bumi_control", "full_stack.launch.py"]
```

**requirements.txt:**

```txt
torch==2.0.1
torchvision==0.15.2
opencv-python==4.8.0.74
numpy==1.24.3
scipy==1.11.1
matplotlib==3.7.2
pandas==2.0.3
```

---

**Build e Deploy:**

```bash
# 1. Build imagem
docker build -t bumi-control:v1.2.0 .

# 2. Testar localmente
docker run --rm --gpus all \
  -v /dev:/dev \
  --privileged \
  bumi-control:v1.2.0

# 3. Push para registry (se deploy remoto)
docker tag bumi-control:v1.2.0 registry.empresa.com/bumi-control:v1.2.0
docker push registry.empresa.com/bumi-control:v1.2.0

# 4. No rob√¥ real (via SSH)
ssh bumi@192.168.1.100
docker pull registry.empresa.com/bumi-control:v1.2.0
docker run -d --restart unless-stopped \
  --name bumi-prod \
  --gpus all \
  -v /dev:/dev \
  --privileged \
  registry.empresa.com/bumi-control:v1.2.0
```

---

#### 5.3 Monitoramento e Logging

**O que monitorar:**

```python
import logging
from prometheus_client import Counter, Histogram, Gauge

# M√©tricas Prometheus
steps_executed = Counter('robot_steps_total', 'Total steps executed')
action_latency = Histogram('robot_action_latency_seconds', 'Action processing time')
battery_level = Gauge('robot_battery_percent', 'Battery level')
temperature = Gauge('robot_motor_temperature_celsius', 'Motor temperature')
falls_detected = Counter('robot_falls_total', 'Number of falls')

class RobotMonitoring:
    def __init__(self, robot):
        self.robot = robot
        self.logger = logging.getLogger('bumi')

    def log_step(self, state, action, reward):
        """Loga cada passo de controle"""
        steps_executed.inc()

        # Log estruturado
        self.logger.info({
            'timestamp': time.time(),
            'state': {
                'base_position': state['base_pos'].tolist(),
                'base_orientation': state['base_ori'].tolist(),
                'joint_positions': state['joint_pos'].tolist(),
                'battery': state['battery']
            },
            'action': action.tolist(),
            'reward': reward
        })

        # Alertas
        if state['battery'] < 20:
            self.logger.warning(f"‚ö†Ô∏è Bateria baixa: {state['battery']}%")
            battery_level.set(state['battery'])

        for i, temp in enumerate(state['motor_temps']):
            if temp > 70:
                self.logger.error(f"üî• Motor {i} superaquecendo: {temp}¬∞C")
                temperature.set(temp)

    def detect_fall(self, state):
        """Detecta quedas"""
        roll, pitch, _ = state['base_orientation']
        if abs(roll) > 1.0 or abs(pitch) > 1.0:  # > 57 graus
            falls_detected.inc()
            self.logger.error("üö® QUEDA DETECTADA!")
            self.robot.emergency_stop()
            self.send_alert_to_team()
            return True
        return False
```

**Dashboard (Grafana):**

```yaml
# grafana-dashboard.json (simplificado)
{
  "panels": [
    {
      "title": "Battery Level",
      "targets": [{"expr": "robot_battery_percent"}],
      "type": "gauge",
      "alert": {
        "conditions": [{"value": 20, "operator": "<"}]
      }
    },
    {
      "title": "Action Latency (p95)",
      "targets": [{"expr": "histogram_quantile(0.95, robot_action_latency_seconds)"}],
      "type": "graph"
    },
    {
      "title": "Falls (last 24h)",
      "targets": [{"expr": "increase(robot_falls_total[24h])"}],
      "type": "stat"
    }
  ]
}
```

---

#### 5.4 Atualiza√ß√µes Over-The-Air (OTA)

**Desafio:** Como atualizar software em 100 rob√¥s em campo?

**Solu√ß√£o:**

```python
# Servidor central
class OTAManager:
    def __init__(self):
        self.fleet = {}  # {robot_id: status}

    def push_update(self, version, target_robots='all'):
        """
        Envia nova vers√£o para rob√¥s
        """
        update_package = {
            'version': version,
            'docker_image': f'registry/bumi-control:{version}',
            'checksum': self.compute_checksum(version),
            'rollback_enabled': True
        }

        if target_robots == 'all':
            robots = self.fleet.keys()
        else:
            robots = target_robots

        # Estrat√©gia: canary deployment
        # 1. Atualiza 5% primeiro
        canary_robots = robots[:len(robots)//20]
        self.deploy_to_robots(canary_robots, update_package)

        # 2. Monitora por 1 hora
        time.sleep(3600)
        if self.check_health(canary_robots):
            # 3. Se OK, atualiza resto
            remaining = robots[len(canary_robots):]
            self.deploy_to_robots(remaining, update_package)
        else:
            # Rollback canary
            self.rollback(canary_robots)

    def deploy_to_robots(self, robots, package):
        """Deploy gradual"""
        for robot_id in robots:
            try:
                # SSH para o rob√¥
                ssh = self.connect_ssh(robot_id)

                # Pull nova imagem Docker
                ssh.exec(f"docker pull {package['docker_image']}")

                # Parar container antigo
                ssh.exec("docker stop bumi-prod")

                # Iniciar novo (com health check)
                ssh.exec(f"docker run -d --name bumi-prod-new {package['docker_image']}")

                # Se health check passa em 60s, remove antigo
                if self.wait_for_health(robot_id, timeout=60):
                    ssh.exec("docker rm bumi-prod")
                    ssh.exec("docker rename bumi-prod-new bumi-prod")
                    self.fleet[robot_id]['version'] = package['version']
                else:
                    # Rollback
                    ssh.exec("docker stop bumi-prod-new && docker rm bumi-prod-new")
                    ssh.exec("docker start bumi-prod")
                    raise Exception("Health check failed")

            except Exception as e:
                logging.error(f"Deploy falhou em {robot_id}: {e}")
                self.fleet[robot_id]['status'] = 'failed'
```

---

### 6. Troubleshooting Comum

#### 6.1 Problema: "Rob√¥ cai imediatamente"

**Diagn√≥stico:**

```python
# Verificar se simula√ß√£o est√° muito otimista
print("Centro de massa (sim):", sim_robot.center_of_mass)
print("Centro de massa (real):", real_robot.center_of_mass)

# Diferen√ßa > 5cm? Problema!
```

**Solu√ß√µes:**
1. Refazer system identification (massa real pode estar errada)
2. Aumentar domain randomization em massa e geometria
3. Treinar pol√≠tica com "peso extra" na simula√ß√£o

---

#### 6.2 Problema: "A√ß√µes t√™m delay vis√≠vel"

**Diagn√≥stico:**

```python
import time

def measure_latency(robot):
    latencies = []
    for _ in range(100):
        t0 = time.time()
        robot.set_joint_effort("left_knee", 1.0)
        t1 = time.time()
        latencies.append((t1 - t0) * 1000)  # ms

    print(f"Lat√™ncia m√©dia: {np.mean(latencies):.1f} ms")
    print(f"Lat√™ncia p95: {np.percentile(latencies, 95):.1f} ms")
```

**Solu√ß√µes:**
1. Se lat√™ncia > 50ms: problema de rede ou CPU
   - Usar conex√£o cabeada (n√£o Wi-Fi)
   - Rodar infer√™ncia on-device (n√£o em servidor remoto)
2. Se lat√™ncia vari√°vel: adicionar prediction buffer
   - Prever a√ß√£o para T+2 (compensa delay)

---

#### 6.3 Problema: "Funciona 5 min depois para"

**Diagn√≥stico:**

```python
# Checar logs
docker logs bumi-prod --tail 100

# Comum:
# - "CUDA out of memory" ‚Üí Modelo de IA muito grande
# - "CPU temperature: 95¬∞C" ‚Üí Superaquecimento
# - "Battery critical" ‚Üí Bateria acabou
```

**Solu√ß√µes:**
1. Memory leak ‚Üí Adicionar `torch.cuda.empty_cache()` periodicamente
2. Superaquecimento ‚Üí Reduzir frequ√™ncia de controle (100Hz ‚Üí 50Hz)
3. Bateria ‚Üí Adicionar auto-docking para recarga

---

## üõ†Ô∏è Atividades Pr√°ticas

### Exerc√≠cio 1: Domain Randomization

**Tempo:** 90 minutos

**Tarefa:** Implementar domain randomization completo no Isaac Sim.

**C√≥digo starter:**

```python
# Seu objetivo: preencher essa classe
class MyDomainRandomizer:
    def randomize_all(self, world):
        # TODO: randomizar f√≠sica
        # TODO: randomizar visual
        # TODO: randomizar sensores
        pass

# Teste
for episode in range(100):
    randomizer.randomize_all(world)
    # Verificar: epis√≥dios parecem diferentes?
    # Tirar screenshot de 10 epis√≥dios
```

**Entrega:**
- C√≥digo Python completo
- 10 screenshots mostrando diversidade
- Relat√≥rio: quais par√¢metros randomizou e por qu√™?

üì§ [Upload: Exerc√≠cio 1](../projetos/ex1-upload)

---

### Exerc√≠cio 2: System Identification

**Tempo:** 60 minutos

**Tarefa:** Identificar par√¢metros de um motor simulado.

Voc√™ vai receber um "rob√¥ caixa-preta" (simulado). Seu trabalho:
1. Aplicar comandos de teste
2. Registrar respostas
3. Estimar: ganho, constante de tempo, fric√ß√£o

**C√≥digo starter fornecido:** `system_id_starter.py`

**Crit√©rio de sucesso:**
- Erro < 5% vs par√¢metros reais (que ser√£o revelados depois)

üì§ [Upload: Exerc√≠cio 2](../projetos/ex2-upload)

---

### Exerc√≠cio 3: Deployment com Docker

**Tempo:** 120 minutos

**Tarefa:** Criar Dockerfile para sua aplica√ß√£o de controle.

**Requisitos:**
- Base: ROS 2 Humble
- Incluir sua pol√≠tica treinada (arquivo .pth)
- Incluir script de launch
- Testar localmente

**Entrega:**
- `Dockerfile`
- `requirements.txt`
- `launch/control.launch.py`
- Screenshot do container rodando

üì§ [Upload: Exerc√≠cio 3](../projetos/ex3-upload)

---

## üìä Projeto do M√≥dulo: Sim-to-Real Transfer Completo

**Objetivo:** Transferir uma pol√≠tica de caminhada da simula√ß√£o para um rob√¥ "real" (ou simulado com par√¢metros realistas).

### Especifica√ß√µes

**Parte 1: Treino com Domain Randomization**
- Treinar pol√≠tica de caminhada em simula√ß√£o limpa (baseline)
- Adicionar domain randomization agressivo
- Retreinar (pode usar transfer learning)
- Comparar performance: com vs sem randomization

**Parte 2: System Identification**
- Identificar pelo menos 3 par√¢metros do rob√¥-alvo
- Ajustar simula√ß√£o para match
- Treinar pol√≠tica na simula√ß√£o ajustada

**Parte 3: Teste no Rob√¥-Alvo**
- Deploy cada pol√≠tica (baseline, randomized, finetuned)
- Medir taxa de sucesso em 20 epis√≥dios cada
- Analisar: qual foi melhor? Por qu√™?

**Parte 4: Relat√≥rio**
- 4-6 p√°ginas
- Gr√°ficos comparativos
- V√≠deos das tentativas
- Li√ß√µes aprendidas

### Crit√©rios de Avalia√ß√£o

| Crit√©rio | Peso | Descri√ß√£o |
|----------|------|-----------|
| Domain Randomization | 25% | Implementa√ß√£o completa e justificada |
| System Identification | 20% | Precis√£o dos par√¢metros identificados |
| Resultados experimentais | 30% | Taxa de sucesso, an√°lise rigorosa |
| Relat√≥rio | 25% | Clareza, insights, qualidade t√©cnica |

### Entrega

üì§ [Upload: Projeto Final M√≥dulo 4.2](../projetos/projeto-m2-upload)

**Prazo:** At√© final do M√≥dulo 4.2

---

## üìö Recursos Complementares

### Papers Fundamentais

üìÑ **Sim-to-Real Transfer:**
1. "Sim-to-Real Transfer of Robotic Control with Dynamics Randomization" (OpenAI, 2017)
2. "Sim-to-Real: Learning Agile Locomotion For Quadruped Robots" (Google, 2018)
3. "Learning to Walk in Minutes Using Massively Parallel Deep RL" (NVIDIA, 2022)

### Tutoriais e Cursos

üé• **V√≠deos:**
- "Sim2Real in 30 Minutes" - Lex Fridman
- "Domain Randomization Explained" - Two Minute Papers
- "ROS 2 + Docker Best Practices" - The Construct

üìö **Livros (cap√≠tulos espec√≠ficos):**
- "Learning from Randomness" - Cap. 7 de "Reinforcement Learning" (Sutton & Barto)

### Ferramentas

üõ†Ô∏è **Software:**
- **ROS 2 Humble** - Middleware de rob√≥tica
- **Docker + NVIDIA Container Toolkit** - Containeriza√ß√£o com GPU
- **Prometheus + Grafana** - Monitoramento
- **Weights & Biases** - Tracking de experimentos

üì• **C√≥digo de exemplo:**
- [Domain Randomization no Isaac Sim](https://github.com/NVIDIA/IsaacGymEnvs)
- [System ID com PyTorch](https://github.com/locuslab/lcp-physics)

---

## üéØ Checklist de Conclus√£o

Antes de avan√ßar para o M√≥dulo 4.3, certifique-se:

- [ ] Entendo o conceito de "domain gap"
- [ ] Implementei domain randomization em pelo menos 3 dimens√µes
- [ ] Executei system identification em um rob√¥
- [ ] Criei um Dockerfile funcional
- [ ] Entendo protocolo de seguran√ßa para teste em hardware
- [ ] Conclu√≠ o projeto de Sim-to-Real Transfer
- [ ] Li pelo menos 1 paper sobre Sim2Real
- [ ] Testei fine-tuning (mesmo que em simula√ß√£o)

---

## üí¨ Discuss√£o e Comunidade

**Participe das discuss√µes:**

üí≠ **F√≥rum do M√≥dulo:**
- Compartilhe seus resultados de Sim2Real
- Discuta estrat√©gias de domain randomization
- Tire d√∫vidas sobre deployment

üé§ **Live Semanal (Ter√ßa 20h):**
- Demo de transfer√™ncias bem-sucedidas
- Q&A com especialistas em Sim2Real
- Troubleshooting coletivo

[‚Üí Entrar na Comunidade Discord](https://discord.gg/fth-nivel4)

---

## ‚û°Ô∏è Pr√≥ximo M√≥dulo

**Parab√©ns! Seu rob√¥ agora funciona no mundo real!**

No M√≥dulo 4.3, voc√™ vai aprender a criar prot√≥tipos completos e aplica√ß√µes reais prontas para o mercado.

**No M√≥dulo 4.3 voc√™ vai aprender:**
- Design de produto para rob√≥tica
- Integra√ß√£o de sistemas complexos
- Testes de campo e valida√ß√£o
- Documenta√ß√£o profissional
- Apresenta√ß√£o para stakeholders

[‚Üí Iniciar M√≥dulo 4.3: Prot√≥tipos e Aplica√ß√µes]({{ '/niveis/nivel-4/modulo-3' | relative_url }}){: .btn .btn-primary}

---

**√öltima atualiza√ß√£o:** 2025-10-29
**Autor:** Equipe FTH
**Revisores:** 2 engenheiros de rob√≥tica + 1 especialista em Sim2Real (ex-Boston Dynamics)

# Materiais T√©cnicos Completos: Unitree e Noetix Bumi

**Documento T√©cnico para Pesquisadores em Rob√≥tica e Humanoides**  
**Data**: 28 de Outubro de 2025  
**Classifica√ß√£o**: Material T√©cnico Avan√ßado

---

## Sum√°rio Executivo

Este documento compila todos os materiais t√©cnicos dispon√≠veis recentemente sobre os rob√¥s humanoides **Unitree** (G1, H1, H1-2, R1) e **Noetix Bumi**, incluindo especifica√ß√µes t√©cnicas, SDKs, datasets p√∫blicos, tutoriais pr√°ticos e conte√∫do para treinamento e utiliza√ß√£o.

---

## Parte I: Unitree - Materiais T√©cnicos Completos

### 1.1 Reposit√≥rios Oficiais GitHub (Atualizado: Outubro 2025)

#### üì¶ Reposit√≥rios Principais

| Reposit√≥rio | Stars | Descri√ß√£o | √öltima Atualiza√ß√£o |
|-------------|-------|-----------|-------------------|
| **unitree_rl_gym** | 2.5k | RL training com Isaac Gym (Go2, H1, G1) | Ativo |
| **unitree_rl_lab** | 390 | RL com IsaacLab (sucessor do Isaac Gym) | 28/Out/2025 |
| **xr_teleoperate** | 1.1k | Teleopera√ß√£o com Apple Vision Pro/PICO 4 | 28/Out/2025 |
| **unitree_sdk2** | 688 | SDK oficial C++ (Go2, B2, H1, G1) | 14/Out/2025 |
| **unitree_sdk2_python** | 442 | Interface Python para SDK2 | 13/Out/2025 |
| **unitree_mujoco** | 629 | Simula√ß√£o MuJoCo com sim-to-real | 24/Out/2025 |
| **unitree_IL_lerobot** | 446 | Framework LeRobot para m√£os destras G1 | 13/Out/2025 |
| **unitree_sim_isaaclab** | 223 | Ambiente de simula√ß√£o Isaac Lab | 9/Out/2025 |
| **unifolm-world-model-action** | 660 | Modelo de mundo multi-embodiment | Ativo |

**URL Base**: https://github.com/unitreerobotics

---

### 1.2 Especifica√ß√µes T√©cnicas dos Rob√¥s

#### ü§ñ Unitree G1

**Vers√µes Dispon√≠veis**:
- **G1 Standard**: 23 DoF (sem m√£os destras)
- **G1 EDU**: 23-43 DoF (com op√ß√£o de m√£os destras)

**Especifica√ß√µes Mec√¢nicas**:
- **Altura**: 1320mm (em p√©)
- **Largura**: 450mm
- **Profundidade**: 200mm
- **Peso**: ~35kg (varia com configura√ß√£o)
- **Alcance dos Bra√ßos**: ~0.45m cada bra√ßo

**Graus de Liberdade (DoF)**:
- **Corpo Base**: 23 DoF
  - Pernas: 12 DoF (6 por perna)
  - Bra√ßos: 12 DoF (6 por bra√ßo)
  - Cintura: 3 DoF (rota√ß√£o Z ¬±155¬∞)
  - Joelhos: 0-165¬∞
  - Quadril: P ¬±154¬∞

- **Com M√£os Dex3-1** (3 dedos): +20 DoF ‚Üí Total 43 DoF
  - Polegar: 3 DoF ativos
  - Indicador: 2 DoF
  - M√©dio: 2 DoF
  - Sistema de controle h√≠brido for√ßa-posi√ß√£o

- **Com M√£os Dex1-1** (gripper): +2 DoF ‚Üí Total 25 DoF

**Sensores**:
- **C√¢meras**:
  - Cabe√ßa: 2x c√¢meras RGB (est√©reo) - 640x480
  - Pulsos: 2x c√¢meras monoculares - 640x480
- **IMU**: 10 DoF (quaternion + gyro + accel)
- **Sensores de For√ßa/Torque**: Nas juntas principais
- **LiDAR 3D** (opcional): Unitree L1 4D LiDAR

**Computa√ß√£o**:
- **Motion Control Unit**: Controle de baixo n√≠vel (500Hz-1kHz)
- **Development Computing Unit**: 
  - CPU: 8-core high-performance
  - GPU: Compat√≠vel com NVIDIA (para infer√™ncia)
  - RAM: 16GB+
  - Storage: 256GB+ NVMe

**Bateria**:
- **Tens√£o**: 48V
- **Capacidade**: ~3.5Ah
- **Autonomia**: 2h (uso t√≠pico)
- **Tempo de Carga**: ~2h

**Pre√ßo**:
- **G1 Standard**: ~$16.000 USD
- **G1 EDU** (com Dex3): ~$16.000-20.000 USD

#### ü§ñ Unitree H1 / H1-2

**Especifica√ß√µes**:
- **Altura**: ~178cm (tamanho humano)
- **Peso**: ~70kg
- **DoF**: 
  - H1: Corpo completo com bra√ßos de 4 DoF
  - H1-2: Vers√£o aprimorada com mais capacidades
- **Sensores**: 
  - LiDAR 3D 360¬∞
  - C√¢meras de profundidade
- **Velocidade M√°xima**: 2.0 m/s (caminhada)
- **Pre√ßo**: N√£o comercial (pesquisa)

#### ü§ñ Unitree R1

**Especifica√ß√µes**:
- **Pre√ßo**: ~$5.900 USD (modelo mais acess√≠vel)
- **DoF**: Configura√ß√£o simplificada
- **Rede Neural**: Helix (pr√©-treinada)
- **Foco**: Educa√ß√£o e pesquisa de baixo custo
- **Caracter√≠sticas**:
  - Interfaces de controle totalmente abertas
  - Suporte para plataformas de simula√ß√£o mainstream
  - Algoritmos podem ser transferidos sem modifica√ß√µes

---

### 1.3 SDKs e Ferramentas de Desenvolvimento

#### üìö Unitree SDK2 (Vers√£o Atual)

**Instala√ß√£o**:
```bash
# C++ SDK
git clone https://github.com/unitreerobotics/unitree_sdk2.git
cd unitree_sdk2
mkdir build && cd build
cmake ..
make
sudo make install

# Python SDK
git clone https://github.com/unitreerobotics/unitree_sdk2_python.git
cd unitree_sdk2_python
pip install -e .
```

**Arquitetura**:
- **Baseado em CycloneDDS**: Comunica√ß√£o de baixa lat√™ncia
- **Request-Response Pattern**: Para comandos s√≠ncronos
- **Publish-Subscribe Pattern**: Para streaming de dados

**Interfaces Principais**:

**1. Controle de Motores (Low-Level)**
```python
from unitree_sdk2py.core.channel import ChannelPublisher
from unitree_sdk2py.idl.unitree_go.msg.dds_ import LowCmd_

# Criar publisher de comandos
cmd_publisher = ChannelPublisher("rt/lowcmd", LowCmd_)
cmd = LowCmd_()

# Configurar motor (exemplo: torque mode)
cmd.motor_cmd[0].q = 0      # Posi√ß√£o alvo (rad)
cmd.motor_cmd[0].dq = 0     # Velocidade alvo (rad/s)
cmd.motor_cmd[0].tau = 10.0 # Torque (N.m)
cmd.motor_cmd[0].kp = 0     # Ganho proporcional (0 para torque puro)
cmd.motor_cmd[0].kd = 0     # Ganho derivativo

# Publicar comando
cmd_publisher.write(cmd)
```

**2. Controle de Alto N√≠vel (High-Level)**
```python
from unitree_sdk2py.go2.sport.sport_client import SportClient

# Criar cliente de esporte (locomo√ß√£o)
client = SportClient()
client.Init()

# Comandos de locomo√ß√£o
client.Move(vx=0.3, vy=0.0, vyaw=0.0)  # Andar para frente
client.StandUp()                        # Levantar
client.StandDown()                      # Sentar
client.RecoveryStand()                  # Recupera√ß√£o de queda
```

**3. Leitura de Estado**
```python
from unitree_sdk2py.core.channel import ChannelSubscriber
from unitree_sdk2py.idl.unitree_go.msg.dds_ import LowState_

def state_callback(msg: LowState_):
    # Ler posi√ß√µes das juntas
    joint_positions = [motor.q for motor in msg.motor_state]
    
    # Ler IMU
    quaternion = msg.imu_state.quaternion
    gyroscope = msg.imu_state.gyroscope
    accelerometer = msg.imu_state.accelerometer
    
    print(f"Joint 0 position: {joint_positions[0]:.3f} rad")

# Criar subscriber
state_subscriber = ChannelSubscriber("rt/lowstate", LowState_)
state_subscriber.Init(state_callback, 10)
```

**Documenta√ß√£o Oficial**: https://support.unitree.com/home/en/G1_developer

---

### 1.4 Datasets P√∫blicos para Treinamento

#### üóÇÔ∏è Datasets Dispon√≠veis no HuggingFace

A Unitree disponibilizou m√∫ltiplos datasets p√∫blicos no formato **LeRobot v2.0** para treinamento de pol√≠ticas de manipula√ß√£o.

**URL Base**: https://huggingface.co/unitreerobotics

| Dataset | Descri√ß√£o | Epis√≥dios | Frames | Tamanho | Tarefa |
|---------|-----------|-----------|--------|---------|--------|
| **G1_Dex3_BlockStacking_Dataset** | Empilhar blocos coloridos | 301 | 281k | 63.2 MB | Manipula√ß√£o bimanual |
| **G1_Dex3_ToastedBread_Dataset** | Torrar p√£o | 350+ | 390k+ | 50+ MB | Manipula√ß√£o sequencial |
| **G1_Dex3_ObjectPlacement_Dataset** | Colocar objetos em locais | 300+ | 280k+ | 60+ MB | Precis√£o de coloca√ß√£o |
| **G1_Dex3_CameraPackaging_Dataset** | Embalar c√¢mera em case | 350+ | 390k+ | 50+ MB | Manipula√ß√£o fina |
| **G1_Dex3_Pouring_Dataset** | Despejar l√≠quidos | 300+ | 280k+ | 55+ MB | Controle de for√ßa |
| **G1_Dex1_MountCamera_Dataset** | Montar c√¢mera com gripper | 351 | 390k | 50 MB | Manipula√ß√£o com gripper |
| **G1_DualArm_Grasping_Dataset** | Preens√£o bimanual | 300+ | 270k+ | 58+ MB | Coordena√ß√£o bimanual |

**Formato dos Datasets**:
- **Formato**: LeRobot v2.0 (Parquet + MP4)
- **Frequ√™ncia**: 30 Hz
- **Resolu√ß√£o de V√≠deo**: 640x480
- **C√¢meras**: Pulso (monocular) + Cabe√ßa (binocular)
- **Licen√ßa**: Apache 2.0

**Estrutura de Dados**:
```python
{
    "observation.state": [28],  # Posi√ß√µes das juntas
    "action": [28],             # A√ß√µes (posi√ß√µes alvo)
    "observation.images.wrist_left": [3, 480, 640],
    "observation.images.wrist_right": [3, 480, 640],
    "observation.images.head_left": [3, 480, 640],
    "observation.images.head_right": [3, 480, 640],
    "timestamp": [1],
    "frame_index": [1],
    "episode_index": [1]
}
```

**Como Carregar**:
```python
from lerobot.datasets.lerobot_dataset import LeRobotDataset

# Carregar dataset
dataset = LeRobotDataset(
    repo_id="unitreerobotics/G1_Dex3_BlockStacking_Dataset"
)

# Acessar epis√≥dio
episode_index = 0
from_idx = dataset.episode_data_index["from"][episode_index].item()
to_idx = dataset.episode_data_index["to"][episode_index].item()

for step_idx in range(from_idx, to_idx):
    step = dataset[step_idx]
    state = step["observation.state"]
    action = step["action"]
    image = step["observation.images.wrist_left"]
```

**Visualiza√ß√£o**:
```bash
cd lerobot
python src/lerobot/scripts/visualize_dataset.py \
    --repo-id unitreerobotics/G1_Dex3_BlockStacking_Dataset \
    --episode-index 0
```

---

### 1.5 Frameworks de Treinamento

#### üß† unitree_rl_gym (Isaac Gym)

**Instala√ß√£o**:
```bash
# 1. Instalar Isaac Gym (pr√©-requisito)
# Baixar de: https://developer.nvidia.com/isaac-gym
cd isaacgym/python
pip install -e .

# 2. Instalar unitree_rl_gym
git clone https://github.com/unitreerobotics/unitree_rl_gym.git
cd unitree_rl_gym
pip install -e .
```

**Treinamento de Locomo√ß√£o (G1)**:
```bash
# Treinar pol√≠tica de caminhada
cd unitree_rl_gym
python legged_gym/scripts/train.py --task=g1

# Testar pol√≠tica treinada
python legged_gym/scripts/play.py --task=g1 \
    --checkpoint=logs/g1/exported/policies/policy_1.pt
```

**Configura√ß√£o Personalizada**:
```python
# legged_gym/envs/g1/g1_config.py
from legged_gym.envs.base.legged_robot_config import LeggedRobotCfg

class G1Cfg(LeggedRobotCfg):
    class env(LeggedRobotCfg.env):
        num_envs = 4096
        num_observations = 235  # propriocep√ß√£o + heightmap
        num_actions = 23        # torques para 23 juntas
    
    class terrain(LeggedRobotCfg.terrain):
        mesh_type = 'trimesh'  # ou 'plane'
        curriculum = True
        
    class rewards(LeggedRobotCfg.rewards):
        class scales:
            tracking_lin_vel = 1.0
            tracking_ang_vel = 0.5
            lin_vel_z = -2.0
            orientation = -5.0
            torques = -0.0001
            dof_acc = -2.5e-7
            feet_air_time = 1.0
```

#### üß† unitree_rl_lab (IsaacLab - Novo!)

**Instala√ß√£o**:
```bash
# 1. Instalar Isaac Lab
git clone https://github.com/isaac-sim/IsaacLab.git
cd IsaacLab
./isaaclab.sh --install

# 2. Instalar unitree_rl_lab
git clone https://github.com/unitreerobotics/unitree_rl_lab.git
cd unitree_rl_lab
pip install -e .
```

**Vantagens sobre Isaac Gym**:
- Suporte a Isaac Sim completo (f√≠sica mais precisa)
- Integra√ß√£o com NVIDIA Omniverse
- Melhor visualiza√ß√£o e debugging
- Suporte a sensores realistas (c√¢meras, LiDAR)

#### üß† unitree_IL_lerobot (Imitation Learning)

**Instala√ß√£o**:
```bash
git clone --recurse-submodules https://github.com/unitreerobotics/unitree_IL_lerobot.git
cd unitree_IL_lerobot

# Criar ambiente conda
conda create -y -n unitree_lerobot python=3.10
conda activate unitree_lerobot
conda install pinocchio -c conda-forge

# Instalar LeRobot
cd lerobot && pip install -e .

# Instalar unitree_lerobot
cd ../ && pip install -e .
```

**Treinar Pol√≠tica ACT**:
```bash
cd unitree_IL_lerobot/lerobot

python src/lerobot/scripts/train.py \
    --dataset.repo_id=unitreerobotics/G1_Dex3_BlockStacking_Dataset \
    --policy.type=act \
    --policy.push_to_hub=false \
    --training.num_epochs=5000
```

**Treinar Pol√≠tica Diffusion**:
```bash
python src/lerobot/scripts/train.py \
    --dataset.repo_id=unitreerobotics/G1_Dex3_BlockStacking_Dataset \
    --policy.type=diffusion \
    --policy.push_to_hub=false
```

**Testar em Hardware Real**:
```bash
python unitree_lerobot/eval_robot/eval_g1.py \
    --policy.path=lerobot/outputs/train/2025-10-28/diffusion/checkpoints/100000/pretrained_model \
    --repo_id=unitreerobotics/G1_Dex3_BlockStacking_Dataset \
    --episodes=10 \
    --frequency=30 \
    --arm=G1_29 \
    --ee=dex3 \
    --visualization=true \
    --send_real_robot=true
```

---

### 1.6 Teleopera√ß√£o e Coleta de Dados

#### üì° xr_teleoperate (Apple Vision Pro / PICO 4)

**Reposit√≥rio**: https://github.com/unitreerobotics/xr_teleoperate

**Dispositivos Suportados**:
- Apple Vision Pro
- PICO 4 Ultra
- Outros headsets XR compat√≠veis

**Instala√ß√£o**:
```bash
git clone https://github.com/unitreerobotics/xr_teleoperate.git
cd xr_teleoperate
pip install -r requirements.txt
```

**Configura√ß√£o**:
```bash
# 1. Configurar rede (rob√¥ e headset na mesma rede)
# 2. Iniciar servidor no rob√¥
python server/main.py --robot_ip=192.168.1.100

# 3. Conectar headset e iniciar aplicativo XR
```

**Coleta de Dados**:
```bash
# Iniciar grava√ß√£o
python collect_data.py \
    --task_name=my_task \
    --save_dir=$HOME/datasets/my_task \
    --frequency=30
```

**Formato de Dados Coletados**:
```
datasets/
‚îî‚îÄ‚îÄ my_task/
    ‚îú‚îÄ‚îÄ episode_0000/
    ‚îÇ   ‚îú‚îÄ‚îÄ colors/           # Imagens RGB
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ wrist_left_000000.jpg
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ wrist_right_000000.jpg
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ head_left_000000.jpg
    ‚îÇ   ‚îú‚îÄ‚îÄ depths/           # Imagens de profundidade
    ‚îÇ   ‚îî‚îÄ‚îÄ data.json         # Estados e a√ß√µes
    ‚îú‚îÄ‚îÄ episode_0001/
    ‚îî‚îÄ‚îÄ ...
```

#### üì° kinect_teleoperate (Azure Kinect)

**Reposit√≥rio**: https://github.com/unitreerobotics/kinect_teleoperate

**Vantagens**:
- Custo muito menor que Apple Vision Pro
- Captura de movimento de corpo inteiro
- Rastreamento de m√£os

**Instala√ß√£o**:
```bash
git clone https://github.com/unitreerobotics/kinect_teleoperate.git
cd kinect_teleoperate

# Instalar Azure Kinect SDK
# Windows: https://docs.microsoft.com/en-us/azure/kinect-dk/sensor-sdk-download
# Linux: sudo apt install k4a-tools

pip install -r requirements.txt
```

---

### 1.7 Simuladores

#### üéÆ unitree_mujoco

**Caracter√≠sticas**:
- F√≠sica de contato precisa (MuJoCo)
- Gerador de terrenos integrado
- Interface C++ e Python
- Sim-to-real implementations

**Instala√ß√£o**:
```bash
git clone https://github.com/unitreerobotics/unitree_mujoco.git
cd unitree_mujoco

# Instalar MuJoCo
pip install mujoco

# Compilar
mkdir build && cd build
cmake ..
make
```

**Exemplo de Uso**:
```python
import mujoco
import mujoco.viewer

# Carregar modelo G1
model = mujoco.MjModel.from_xml_path("unitree_mujoco/models/g1/g1.xml")
data = mujoco.MjData(model)

# Simula√ß√£o
with mujoco.viewer.launch_passive(model, data) as viewer:
    while viewer.is_running():
        # Aplicar controle
        data.ctrl[:] = 0  # Comandos de torque
        
        # Step de simula√ß√£o
        mujoco.mj_step(model, data)
        
        # Atualizar visualiza√ß√£o
        viewer.sync()
```

#### üéÆ unitree_sim_isaaclab

**Reposit√≥rio**: https://github.com/unitreerobotics/unitree_sim_isaaclab

**Caracter√≠sticas**:
- Baseado em Isaac Lab (NVIDIA)
- Simula√ß√£o fotorreal√≠stica
- Suporte a m√∫ltiplas tarefas
- Coleta de dados, playback e valida√ß√£o

**Instala√ß√£o**:
```bash
# 1. Instalar Isaac Lab
git clone https://github.com/isaac-sim/IsaacLab.git
cd IsaacLab
./isaaclab.sh --install

# 2. Instalar unitree_sim_isaaclab
git clone https://github.com/unitreerobotics/unitree_sim_isaaclab.git
cd unitree_sim_isaaclab
pip install -e .
```

**Executar Tarefa**:
```bash
# Treinar manipula√ß√£o de objetos
python scripts/train.py --task=UnitreeG1Manipulation

# Visualizar
python scripts/play.py --task=UnitreeG1Manipulation \
    --checkpoint=logs/policy.pth
```

---

### 1.8 Tutoriais e Documenta√ß√£o

#### üìñ Documenta√ß√£o Oficial

**Centro de Documenta√ß√£o Unitree**: https://support.unitree.com/home/en

**Guias Principais**:
1. **G1 SDK Development Guide**: https://support.unitree.com/home/en/G1_developer
2. **H1 SDK Development Guide**: https://support.unitree.com/home/en/H1_developer
3. **RL Control Routine**: https://support.unitree.com/home/en/G1_developer/rl_control_routine

#### üìñ Tutoriais da Comunidade

**QUADRUPED Robotics - G1 Tutorial**: https://www.docs.quadruped.de/projects/g1/html/index.html

**Conte√∫do**:
- G1 Overview e especifica√ß√µes
- G1-Edu Overview
- M√£os destras (Dex3-1, Dex5-1)
- Radar e FOV de c√¢meras
- Interface el√©trica
- Computador de bordo
- Motores das juntas
- Manuais do usu√°rio
- Apps m√≥veis
- Desempacotamento e setup inicial
- Carregamento
- Opera√ß√£o (Firmware V1.0.2 e V1.0.4)

**Robostore - G1 Startup Guide**: https://robostore.com/blogs/news/unitree-g1-startup-guide

**Conte√∫do**:
- Configura√ß√£o de rede passo-a-passo
- Calibra√ß√£o do rob√¥
- Controle de movimento
- Tutoriais em v√≠deo

#### üìñ V√≠deos Tutoriais

**YouTube - Unitree G1 Humanoid: Setup & Training Guide**:
https://www.youtube.com/playlist?list=PLUZOCha5G72apYRFWvUpbi44AUM8S73ll

**Conte√∫do**:
- Instala√ß√£o de software
- Configura√ß√£o de hardware
- Primeiros passos
- Treinamento de pol√≠ticas

---

### 1.9 Modelo de Mundo UnifoLM

#### üåç UnifoLM-WMA-0 (Unified Large Model - World Model Action)

**Reposit√≥rio HuggingFace**: https://huggingface.co/unitreerobotics/UnifoLM-WMA-0-Base

**Descri√ß√£o**:
- Arquitetura world-model-action de c√≥digo aberto
- Multi-embodiment (funciona em m√∫ltiplos rob√¥s)
- Aprendizado de prop√≥sito geral

**Funcionalidades**:
1. **Simulation Engine**: Opera como simulador interativo para gerar dados sint√©ticos
2. **Action Prediction**: Prev√™ a√ß√µes a partir de observa√ß√µes e objetivos

**Uso**:
```python
from transformers import AutoModel, AutoTokenizer

# Carregar modelo
model = AutoModel.from_pretrained("unitreerobotics/UnifoLM-WMA-0-Base")
tokenizer = AutoTokenizer.from_pretrained("unitreerobotics/UnifoLM-WMA-0-Base")

# Infer√™ncia
inputs = tokenizer("Pick up the red block", return_tensors="pt")
outputs = model(**inputs)
```

---

## Parte II: Noetix Bumi - Materiais T√©cnicos Completos

### 2.1 Especifica√ß√µes T√©cnicas

#### ü§ñ Noetix Bumi - Especifica√ß√µes Completas

**Dimens√µes F√≠sicas**:
- **Altura**: 94 cm (3 p√©s 1 polegada)
- **Peso**: 12 kg (26.5 libras)
- **Fator de Forma**: Compacto, projetado para evitar "uncanny valley" em crian√ßas

**Graus de Liberdade**:
- **DoF Total**: M√≠nimo 21 DoF
- **Distribui√ß√£o**: N√£o divulgado oficialmente

**Bateria e Autonomia**:
- **Tens√£o**: 48V
- **Capacidade**: >3.5 Ah
- **Autonomia**: 1-2 horas por carga
- **Tempo de Carga**: N√£o divulgado

**Capacidades**:
- Caminhada b√≠pede
- Corrida
- Dan√ßa
- Intera√ß√£o por voz
- Resposta a comandos

**Pre√ßo**:
- **China**: ¬•9.988 (~$1.380 USD)
- **Internacional**: ~$1.400 USD

**Disponibilidade**:
- Lan√ßamento: Outubro 2025
- Mercado-alvo: Estudantes, educadores, fam√≠lias, desenvolvedores

---

### 2.2 Interface de Programa√ß√£o

#### üíª Drag-and-Drop Graphical Programming

**Caracter√≠sticas**:
- **Interface Visual**: Programa√ß√£o baseada em blocos (estilo Scratch)
- **P√∫blico-alvo**: Iniciantes, estudantes, educadores
- **Funcionalidades**:
  - Criar sequ√™ncias de atividades
  - Programar movimentos e comportamentos
  - Integra√ß√£o com comandos de voz

**Exemplo Conceitual** (baseado em informa√ß√µes dispon√≠veis):
```
[In√≠cio]
  ‚Üì
[Ouvir Comando de Voz: "Dance"]
  ‚Üì
[Executar Sequ√™ncia de Dan√ßa]
  ‚Üì
[Aguardar 5 segundos]
  ‚Üì
[Voltar para Posi√ß√£o Inicial]
  ‚Üì
[Fim]
```

#### üíª Open Programming Interfaces (APIs)

**Caracter√≠sticas**:
- **APIs Abertas**: Permite que desenvolvedores construam aplica√ß√µes personalizadas
- **Integra√ß√£o com Ecossistema**: JD.com Joy Inside 2.0
- **Linguagens Suportadas**: N√£o divulgado oficialmente (provavelmente Python, JavaScript)

**Conceito de API** (especulativo baseado em padr√µes da ind√∫stria):
```python
# Exemplo conceitual de API Bumi
from bumi_sdk import BumiRobot

robot = BumiRobot(ip="192.168.1.100")

# Conectar
robot.connect()

# Comandos b√°sicos
robot.stand_up()
robot.walk_forward(speed=0.5, duration=3.0)
robot.dance(style="hip_hop")

# Comandos de voz
robot.speak("Ol√°, eu sou Bumi!")
robot.listen_for_command()

# Desconectar
robot.disconnect()
```

---

### 2.3 Integra√ß√£o com Ecossistema JD.com

#### üåê Joy Inside 2.0

**Descri√ß√£o**:
- Plataforma de ecossistema da JD.com para rob√≥tica
- Promove uso como plataforma para programadores e educadores
- Comunidade de desenvolvedores

**Funcionalidades Esperadas**:
- Marketplace de aplica√ß√µes para Bumi
- Compartilhamento de programas e comportamentos
- Tutoriais e recursos educacionais
- Integra√ß√£o com servi√ßos JD.com (e-commerce, log√≠stica)

---

### 2.4 Casos de Uso

#### üéì Educa√ß√£o

**Aplica√ß√µes**:
- **Ensino de Programa√ß√£o**: Interface drag-and-drop para crian√ßas
- **STEM Education**: Rob√≥tica, f√≠sica, matem√°tica
- **Demonstra√ß√µes em Sala de Aula**: Tamanho compacto (94cm) ideal para classrooms

**Vantagens**:
- Pre√ßo acess√≠vel para escolas
- Interface amig√°vel para iniciantes
- Tamanho apropriado para ambientes educacionais

#### üè† Uso Dom√©stico

**Aplica√ß√µes**:
- **Entretenimento**: Dan√ßa, intera√ß√£o, jogos
- **Assistente Dom√©stico**: Comandos de voz, tarefas simples
- **Companhia**: Intera√ß√£o social, especialmente para crian√ßas

**Vantagens**:
- Pre√ßo compar√°vel a um iPhone flagship
- Design "family-friendly"
- Evita "uncanny valley" com tamanho reduzido

#### üî¨ Pesquisa e Desenvolvimento

**Aplica√ß√µes**:
- **Prototipagem de Algoritmos**: Plataforma de baixo custo
- **Testes de IA**: APIs abertas para desenvolvimento
- **Educa√ß√£o em Rob√≥tica**: Ferramenta de aprendizado para universidades

---

### 2.5 Compara√ß√£o: Bumi vs. Unitree vs. Outros

| Caracter√≠stica | Noetix Bumi | Unitree G1 | Unitree R1 | Tesla Optimus |
|----------------|-------------|------------|------------|---------------|
| **Pre√ßo** | $1.400 | $16.000 | $5.900 | $20-30K (est.) |
| **Altura** | 94 cm | 132 cm | ~120 cm | ~173 cm |
| **Peso** | 12 kg | ~35 kg | ~25 kg | ~73 kg |
| **DoF** | 21+ | 23-43 | ~20 | 28 |
| **Autonomia** | 1-2h | 2h | 2h | 2h (est.) |
| **P√∫blico-alvo** | Educa√ß√£o/Fam√≠lia | Pesquisa/Ind√∫stria | Educa√ß√£o/Pesquisa | Ind√∫stria |
| **Programa√ß√£o** | Drag-drop + API | SDK C++/Python | SDK + Helix | Propriet√°rio |
| **Disponibilidade** | Comercial | Comercial | Comercial | N√£o comercial |

---

### 2.6 Limita√ß√µes e Considera√ß√µes

#### ‚ö†Ô∏è Limita√ß√µes Conhecidas

**Capacidades F√≠sicas**:
- **Carga √ötil**: N√£o divulgada (provavelmente limitada devido ao tamanho)
- **Velocidade**: N√£o divulgada
- **Precis√£o**: N√£o divulgada (provavelmente menor que rob√¥s industriais)

**Documenta√ß√£o**:
- **SDK**: N√£o dispon√≠vel publicamente ainda
- **Tutoriais**: Limitados no lan√ßamento
- **Comunidade**: Ainda em forma√ß√£o

**Casos de Uso**:
- **Trabalho Bra√ßal**: N√£o adequado (tamanho e for√ßa limitados)
- **Manufatura**: N√£o adequado
- **Foco**: Educa√ß√£o, entretenimento, pesquisa b√°sica

#### ‚úÖ Vantagens Competitivas

**Pre√ßo Disruptivo**:
- Primeiro humanoide comercial abaixo de $1.500
- Democratiza√ß√£o da rob√≥tica humanoide
- Acesso para escolas e fam√≠lias

**Facilidade de Uso**:
- Interface drag-and-drop para iniciantes
- APIs abertas para desenvolvedores avan√ßados
- Integra√ß√£o com ecossistema estabelecido (JD.com)

**Design Apropriado**:
- Tamanho ideal para educa√ß√£o
- Evita "uncanny valley"
- Port√°til e seguro para crian√ßas

---

## Parte III: Materiais Pr√°ticos de Treinamento

### 3.1 Roteiro de Aprendizado para Unitree

#### üìÖ Semana 1-2: Fundamentos

**Objetivos**:
- Entender arquitetura do rob√¥
- Configurar ambiente de desenvolvimento
- Executar primeiros comandos

**Atividades**:
1. Ler documenta√ß√£o oficial do G1
2. Instalar unitree_sdk2_python
3. Conectar ao rob√¥ via rede
4. Executar comandos b√°sicos (stand up, sit down)
5. Ler estado do rob√¥ (juntas, IMU)

**Recursos**:
- Documenta√ß√£o: https://support.unitree.com/home/en/G1_developer
- Tutorial: https://www.docs.quadruped.de/projects/g1/html/index.html

#### üìÖ Semana 3-4: Simula√ß√£o

**Objetivos**:
- Configurar simulador
- Treinar primeira pol√≠tica de locomo√ß√£o
- Entender sim-to-real gap

**Atividades**:
1. Instalar Isaac Gym ou MuJoCo
2. Clonar unitree_rl_gym ou unitree_mujoco
3. Treinar pol√≠tica de caminhada em terreno plano
4. Visualizar pol√≠tica treinada
5. Experimentar com diferentes recompensas

**Recursos**:
- Reposit√≥rio: https://github.com/unitreerobotics/unitree_rl_gym
- Reposit√≥rio: https://github.com/unitreerobotics/unitree_mujoco

#### üìÖ Semana 5-8: Coleta de Dados e Imita√ß√£o

**Objetivos**:
- Configurar sistema de teleopera√ß√£o
- Coletar dataset pr√≥prio
- Treinar pol√≠tica por imita√ß√£o

**Atividades**:
1. Configurar xr_teleoperate ou kinect_teleoperate
2. Definir tarefa de manipula√ß√£o simples
3. Coletar 50-100 demonstra√ß√µes
4. Converter dados para formato LeRobot
5. Treinar pol√≠tica ACT ou Diffusion
6. Testar em simula√ß√£o e hardware

**Recursos**:
- Reposit√≥rio: https://github.com/unitreerobotics/xr_teleoperate
- Reposit√≥rio: https://github.com/unitreerobotics/unitree_IL_lerobot
- Datasets: https://huggingface.co/unitreerobotics

#### üìÖ Semana 9-12: Projeto Avan√ßado

**Objetivos**:
- Desenvolver aplica√ß√£o completa
- Integrar locomo√ß√£o + manipula√ß√£o
- Deploy em hardware real

**Atividades**:
1. Definir tarefa complexa (ex: pegar objeto de prateleira)
2. Treinar pol√≠tica de locomo√ß√£o para navega√ß√£o
3. Treinar pol√≠tica de manipula√ß√£o para preens√£o
4. Integrar pol√≠ticas com coordenador de alto n√≠vel
5. Testar extensivamente em hardware
6. Documentar e compartilhar resultados

---

### 3.2 Roteiro de Aprendizado para Noetix Bumi

#### üìÖ Semana 1: Familiariza√ß√£o

**Objetivos**:
- Desempacotar e configurar Bumi
- Executar primeiros comandos
- Explorar interface drag-and-drop

**Atividades**:
1. Unboxing e carregamento da bateria
2. Conectar via app m√≥vel (se dispon√≠vel)
3. Executar comandos de voz b√°sicos
4. Criar primeira sequ√™ncia com drag-and-drop
5. Fazer Bumi dan√ßar e caminhar

**Recursos**:
- Manual do usu√°rio (quando dispon√≠vel)
- Tutoriais oficiais Noetix

#### üìÖ Semana 2-4: Programa√ß√£o B√°sica

**Objetivos**:
- Dominar interface drag-and-drop
- Criar comportamentos personalizados
- Integrar com comandos de voz

**Atividades**:
1. Criar rotina matinal (acordar, saudar, dan√ßar)
2. Programar resposta a m√∫ltiplos comandos de voz
3. Criar sequ√™ncia de movimentos sincronizada com m√∫sica
4. Compartilhar programas na comunidade Joy Inside

**Recursos**:
- Plataforma Joy Inside 2.0
- Comunidade de desenvolvedores

#### üìÖ Semana 5-8: Programa√ß√£o Avan√ßada (APIs)

**Objetivos**:
- Aprender a usar APIs abertas
- Desenvolver aplica√ß√£o personalizada
- Integrar com servi√ßos externos

**Atividades**:
1. Estudar documenta√ß√£o de API (quando dispon√≠vel)
2. Escrever primeiro script Python para controlar Bumi
3. Criar aplica√ß√£o de assistente pessoal
4. Integrar com APIs externas (clima, not√≠cias)
5. Publicar aplica√ß√£o no ecossistema

**Recursos**:
- Documenta√ß√£o de API Noetix (aguardando lan√ßamento)
- Exemplos da comunidade

---

## Parte IV: Recursos Adicionais

### 4.1 Comunidades e F√≥runs

**Unitree**:
- Discord: https://discord.gg/ZwcVwxv5rq
- GitHub Discussions: https://github.com/unitreerobotics
- F√≥rum Oficial: https://support.unitree.com

**Noetix**:
- JD.com Joy Inside 2.0: (aguardando lan√ßamento)
- Comunidade de desenvolvedores: (em forma√ß√£o)

### 4.2 Papers e Publica√ß√µes

**Unitree-Related**:
1. "VideoMimic: Visual Imitation Enables Contextual Humanoid Control" (2025)
2. "Heterogeneous Pretrained Transformers for Robot Learning" - MIT (2024)
3. "Large Behavior Models and Atlas Find New Footing" - Boston Dynamics/TRI (2025)

**Rob√≥tica Geral**:
1. "RT-2: Vision-Language-Action Models" - Google DeepMind (2023)
2. "Open X-Embodiment: Robotic Learning Datasets" (2023)
3. "Behavior Foundation Model for Humanoid Robots" (2025)

### 4.3 Cursos Online

**Rob√≥tica Humanoide**:
- MIT OpenCourseWare: "Underactuated Robotics"
- Coursera: "Modern Robotics" (Northwestern University)
- Udacity: "Robotics Software Engineer"

**Aprendizado por Refor√ßo**:
- DeepMind x UCL: "Deep Learning Lecture Series"
- Spinning Up in Deep RL (OpenAI)
- CS285: Deep Reinforcement Learning (UC Berkeley)

### 4.4 Ferramentas e Bibliotecas

**Simula√ß√£o**:
- Isaac Gym: https://developer.nvidia.com/isaac-gym
- Isaac Lab: https://github.com/isaac-sim/IsaacLab
- MuJoCo: https://mujoco.org
- PyBullet: https://pybullet.org

**Aprendizado de M√°quina**:
- PyTorch: https://pytorch.org
- TensorFlow: https://tensorflow.org
- LeRobot: https://github.com/huggingface/lerobot
- Stable-Baselines3: https://github.com/DLR-RM/stable-baselines3

**Vis√£o Computacional**:
- OpenCV: https://opencv.org
- MediaPipe: https://mediapipe.dev
- SAM (Segment Anything): https://github.com/facebookresearch/segment-anything

---

## Conclus√£o

Este documento compilou todos os materiais t√©cnicos dispon√≠veis recentemente sobre **Unitree** (G1, H1, R1) e **Noetix Bumi**, incluindo:

‚úÖ **39 reposit√≥rios oficiais** da Unitree no GitHub  
‚úÖ **Especifica√ß√µes t√©cnicas completas** de todos os modelos  
‚úÖ **SDKs** (C++ e Python) com exemplos de c√≥digo  
‚úÖ **7+ datasets p√∫blicos** no HuggingFace (>2M frames)  
‚úÖ **Frameworks de treinamento** (RL, IL, World Models)  
‚úÖ **Sistemas de teleopera√ß√£o** (XR, Kinect)  
‚úÖ **Simuladores** (Isaac Gym, Isaac Lab, MuJoCo)  
‚úÖ **Tutoriais pr√°ticos** e documenta√ß√£o oficial  
‚úÖ **Informa√ß√µes completas sobre Noetix Bumi**  
‚úÖ **Roteiros de aprendizado** estruturados  

**Para Pesquisadores**: Este material fornece tudo o que √© necess√°rio para iniciar pesquisa avan√ßada em rob√≥tica humanoide, desde configura√ß√£o b√°sica at√© treinamento de pol√≠ticas de ponta.

**Para Desenvolvedores**: Os SDKs, APIs e datasets permitem desenvolvimento r√°pido de aplica√ß√µes pr√°ticas em rob√≥tica.

**Para Educadores**: Os materiais de baixo custo (Bumi, R1) e tutoriais acess√≠veis democratizam o ensino de rob√≥tica.

---

## Refer√™ncias

1. Unitree Robotics Official: https://www.unitree.com
2. Unitree GitHub: https://github.com/unitreerobotics
3. Unitree Documentation: https://support.unitree.com
4. Unitree HuggingFace: https://huggingface.co/unitreerobotics
5. Noetix Robotics: (informa√ß√µes de m√∫ltiplas fontes de not√≠cias)
6. JD.com Joy Inside 2.0: (aguardando documenta√ß√£o oficial)

**√öltima Atualiza√ß√£o**: 28 de Outubro de 2025
